{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyteomics import pepxml\n",
    "from pyteomics import mzml\n",
    "from pyteomics import mzid\n",
    "from pyteomics import parser\n",
    "from pyteomics.mass import unimod\n",
    "from pyteomics import electrochem\n",
    "import os\n",
    "from lxml import etree\n",
    "from Bio import SeqIO\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "project = '/home/ismael/palaeoproteomics/BLG'\n",
    "n_procs = 6"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process software results\n",
    "\n",
    "We want to extract equivalent PSM information from Mascot, Fragpipe, pFind, MaxQuant, Alphapepet and Metamorpheus.\n",
    "we will go throigh each run and sample and put the PSM data into a dataframe.\n",
    "Then we will concatenate the results.\n",
    "\n",
    "For *de novo* we will do the same, but since it is all done on DeNovoGUI, all the data is already combined."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmark table\n",
    "\n",
    "Read and format to use later. It contains software run information"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "benchmark_table = pd.read_csv(os.path.join(project, 'benchmark_table.csv'), header=0)\n",
    "benchmark_table"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BLG and databases\n",
    "\n",
    "Read database FASTA files and store BLG sequence IDs\n",
    "\n",
    "Then we will count how many peptides each digestion type produces for each database"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "fasta_db1_file = os.path.join(project, 'databases/DB1_all_annotated_dairy_BLG_variants_ArchaecRAP3.2_nodups.fasta')\n",
    "fasta_db2_file = os.path.join(project, 'databases/DB2_Bovinae_Proteome_BLG_variants_ArchaecRAP3.2_nodups.fasta')\n",
    "\n",
    "fasta_db = {'DB1': SeqIO.to_dict(SeqIO.parse(fasta_db1_file, format='fasta')),\n",
    "            'DB2': SeqIO.to_dict(SeqIO.parse(fasta_db2_file, format='fasta'))}\n",
    "fasta_list = {'DB1': list(SeqIO.parse(fasta_db1_file, format='fasta')),\n",
    "              'DB2': list(SeqIO.parse(fasta_db2_file, format='fasta'))}\n",
    "\n",
    "decoy_tag = 'rev_'\n",
    "decoy_tag_metam = 'DECOY_'\n",
    "\n",
    "# Create a different fasta_db for Metamorpheus\n",
    "accession_re = re.compile(r'\\|(\\w+)\\|')\n",
    "fasta_db_metam = {}\n",
    "for db in fasta_db.keys():\n",
    "    fasta_db_metam[db] = {}\n",
    "    fasta_db_metam[db]['P02754'] = fasta_db[db]['sp|P02754A|LACB_BOVIN']\n",
    "    fasta_db_metam[db][decoy_tag_metam+'P02754'] = fasta_db[db][decoy_tag+'sp|P02754A|LACB_BOVIN']\n",
    "    for id, seq_rec in fasta_db[db].items():\n",
    "        acc = accession_re.search(id).group(1)\n",
    "        if id.startswith(decoy_tag):\n",
    "            acc = decoy_tag_metam + acc\n",
    "        fasta_db_metam[db][acc] = seq_rec"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(fasta_list['DB1']))\n",
    "print(len(fasta_list['DB2']))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "bovin_lacb = {\n",
    "    'sp|P02754A|LACB_BOVIN', 'P02754A',\n",
    "    'sp|P02754B|LACB_BOVIN', 'P02754B',\n",
    "    'sp|P02754C|LACB_BOVIN', 'P02754C',\n",
    "    'sp|P02754D|LACB_BOVIN', 'P02754D',\n",
    "    'P02754'\n",
    "}\n",
    "\n",
    "other_lacb = {\n",
    "    'sp|P02755|LACB_BUBBU', 'P02755',\n",
    "    'sp|P02756|LACB_CAPHI', 'P02756',\n",
    "    'sp|P02758|LACB1_HORSE', 'P02758',\n",
    "    'sp|P04119|LACB_PIG', 'P04119',\n",
    "    'sp|P07380|LACB2_HORSE', 'P07380',\n",
    "    'sp|P11944|LACB_MACGI', 'P11944',\n",
    "    'sp|P13613|LACB1_EQUAS', 'P13613',\n",
    "    'sp|P19647|LACB2_EQUAS', 'P19647',\n",
    "    'sp|P21664|LACB2_FELCA', 'P21664',\n",
    "    'sp|P33685|LACB1_CANLF', 'P33685',\n",
    "    'sp|P33686|LACB2_CANLF', 'P33686',\n",
    "    'sp|P33687|LACB1_FELCA', 'P33687',\n",
    "    'sp|P33688|LACB3_FELCA', 'P33688',\n",
    "    'sp|P67975|LACB_OVIMU', 'P67975',\n",
    "    'sp|P67976|LACB_SHEEP', 'P67976',\n",
    "    'sp|Q29614|LACB_MACEU', 'Q29614'\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Count peptides"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "parser.expasy_rules"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Enzyte, semispecific or not, and # of missed cleavages\n",
    "# For unspecific, # missed cleavages is equal to max pep length\n",
    "calc_peptides = False\n",
    "\n",
    "if calc_peptides:\n",
    "    digestion = {'tryptic': ['trypsin', False, 2],\n",
    "                'semi_trypsin': ['trypsin', True, 2],\n",
    "                 'non_specific': ['', True, 25]}\n",
    "    dbs = ['DB1', 'DB2']\n",
    "\n",
    "    for db in dbs:\n",
    "        for dig_type, rules in digestion.items():\n",
    "            n_peptides = 0\n",
    "            for seq_record in fasta_list[db]:\n",
    "                if seq_record.id.startswith(decoy_tag):\n",
    "                    continue\n",
    "                digested = parser.cleave(\n",
    "                    str(seq_record.seq),\n",
    "                    rule = parser.expasy_rules.get(rules[0], ''),\n",
    "                    semi = rules[1],\n",
    "                    missed_cleavages = rules[2],\n",
    "                    min_length = 7, max_length = 25)\n",
    "                n_peptides += len(digested)\n",
    "            print(f'{db} {dig_type}: {n_peptides}')\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read mzML spectra files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "folder = '/home/ismael/palaeoproteomics/BLG/mzml_files'\n",
    "mzml_paths = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.mzML')]\n",
    "samples = [os.path.basename(f).rstrip('.mzML') for f in mzml_paths]\n",
    "print(samples)\n",
    "print(mzml_paths)\n",
    "\n",
    "sample_names = {'N0000': '0 days', 'N0040': '4 days' , 'N1280': '128 days'}"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def count_spectra(paths):\n",
    "    # This function counts MS1 and MS2 spectra\n",
    "    scan_counts = []\n",
    "    for p in paths:\n",
    "        file = os.path.basename(p)\n",
    "        sample = file.rstrip('.mzML')\n",
    "        tree = etree.parse(p)\n",
    "        root = tree.getroot()\n",
    "        ms1spectra =  root.xpath(\n",
    "            \"mzml:mzML/mzml:run/mzml:spectrumList/mzml:spectrum\"\n",
    "            \"[mzml:cvParam/@name='ms level' and mzml:cvParam/@value='1']\",\n",
    "            namespaces={'mzml':'http://psi.hupo.org/ms/mzml'})\n",
    "        ms2spectra =  root.xpath(\n",
    "            \"mzml:mzML/mzml:run/mzml:spectrumList/mzml:spectrum\"\n",
    "            \"[mzml:cvParam/@name='ms level' and mzml:cvParam/@value='2']\",\n",
    "            namespaces={'mzml':'http://psi.hupo.org/ms/mzml'})\n",
    "        scan_counts.append([sample, len(ms1spectra), len(ms2spectra)])\n",
    "    n_scans = pd.DataFrame(scan_counts, columns=['Sample', 'n_ms1scans', 'n_ms2scans'])\n",
    "    return n_scans"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "if os.path.exists(os.path.join(project,'analysis_results/n_scans_samples.csv')):\n",
    "    n_scans = pd.read_csv(os.path.join(project,'analysis_results/n_scans_samples.csv'))\n",
    "else:\n",
    "    n_scans = count_spectra(mzml_paths)\n",
    "    n_scans.to_csv(os.path.join(project,'analysis_results/n_scans_samples.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Some software don't report RT in their output, \n",
    "# so we keep the spectra to query for each spectrum retention time\n",
    "spectra_dict = {}\n",
    "for p in mzml_paths:\n",
    "    file = os.path.basename(p)\n",
    "    sample = file.rstrip('.mzML')\n",
    "    mzml_spectra = mzml.read(p, use_index=True)\n",
    "    spectra_dict[sample] = mzml_spectra"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "SCAN INDEX IS 0-BASED AND GOES WITH ARRAY INDEX\n",
    "SCAN NUMBER AND SPECTRUM TITLE/NAME ARE 1-BASED"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PTMs\n",
    "Load Unimod database"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "unimod_db = unimod.Unimod()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "unknown_mods = {'C+12'}\n",
    "map_mods = {'DiDehydro': 'Didehydro',\n",
    "            'Bodipy': 'ZGB'}\n",
    "add_colon = ('Cation', 'Xlink', 'Unknown', 'Biotin_Thermo')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions and globals\n",
    "Define some common functions to read PSMs data from different software and formats:\n",
    "- `get_prot_info`\n",
    "    We will always reference BLG position wrt to bovinBLG if present among identified proteins\n",
    "- `get_rt`\n",
    "\n",
    "Define some global variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_prot_info(pept_seq, proteins, bovin_lacb, other_lacb, fdb, field='protein'):\n",
    "    \"\"\"\n",
    "    Return the start and end of a peptide sequence within a protein, using a list of identified proteins\n",
    "    If present, it preferentially uses a bovin LACB to get the start and end. Otherwise any other LACB\n",
    "    If none are present, it will use the first protein in the list\n",
    "    It needs a dictionary of protein ID keys to Bio.SeqRecord objects\n",
    "    :param pept_seq: Peptide sequence\n",
    "    :param proteins: List of strings or dicts. Strings are protein IDs, if dicts they contain protein ID in field\n",
    "    :param bovin_lacb: List of bovin LACB IDs\n",
    "    :param other_lacb: List of other LACBs\n",
    "    :param fdb: Dictionary of Bio.SeqRecords as returned by SeqIO.to_dict\n",
    "    :param field: f proteins is list of dicts, name of field that contains the ID\n",
    "    :return: protein id, start and end (0-based)\n",
    "    \"\"\"\n",
    "\n",
    "    # See if peptide matches to any LACB\n",
    "    prot_id = proteins[0][field] if field != '' else proteins[0]\n",
    "    for p in proteins:\n",
    "        p = p[field] if field != '' else p\n",
    "        if p in bovin_lacb:\n",
    "            prot_id = p\n",
    "            break\n",
    "        if p in other_lacb:\n",
    "            prot_id = p\n",
    "    # Get protein sequence using prot_id and get peptide start and end\n",
    "    seq_rec = fdb.get(prot_id, None)\n",
    "    if seq_rec is None:\n",
    "        return '', -1, -1\n",
    "    prot_seq = seq_rec.seq\n",
    "    pstart = prot_seq.find(pept_seq)\n",
    "    pend = pstart + len(pept_seq) - 1\n",
    "    return prot_id, pstart, pend\n",
    "\n",
    "\n",
    "def get_rt(scan_ns, mzml_spectra):\n",
    "    \"\"\"\n",
    "    Given a list of scan numbers, it retrieves the RT from mzML pyteomics object\n",
    "    :param scan_ns: List of scan numbers\n",
    "    :param mzml_spectra: mzML object\n",
    "    :return: DataFrame with columns scan index and RTsec\n",
    "    \"\"\"\n",
    "    scan_idx = scan_ns - 1\n",
    "    sel_mzml = mzml_spectra[scan_idx.tolist()]\n",
    "    rt_list = []\n",
    "    for i in range(len(scan_idx)):\n",
    "        rt = sel_mzml[i]['scanList']['scan'][0]['scan start time'] * 60\n",
    "        rt_list.append([scan_idx[i], rt])\n",
    "    return pd.DataFrame(rt_list, columns=['Scan_idx', 'RTsec'])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a PepXML data extractor that works for Mascot and Fragpipe pepXML flavours"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class PepXMLdataExtractor:\n",
    "    \"\"\"\n",
    "    Extracts data from pyteomics pepxml object. The object is callable and can be passed to\n",
    "    the pepxml map method to extractdata from PSMs.\n",
    "    It works with Mascot and FragPipe pepxml flavours\n",
    "    \"\"\"\n",
    "    def __init__(self, flavour):\n",
    "        self.empty_pept_seq = ''\n",
    "        self.empty_prot_id = ''\n",
    "        self.empty_pstart = -1\n",
    "        self.empty_pend = -1\n",
    "        self.empty_isdecoy = None\n",
    "        self.empty_delta_mass = np.nan\n",
    "        self.empty_calc_mass = np.nan\n",
    "        self.empty_qval_key = np.nan\n",
    "        self.empty_scan_no = -1\n",
    "        self.empty_rt = np.nan\n",
    "        self.empty_score = np.nan\n",
    "        if flavour == 'mascot':\n",
    "            self.qval_key_f = self.mascot_expectation\n",
    "            self.scan_no_f = self.mascot_scan_no\n",
    "            self.rt_f = self.mascot_rt\n",
    "            self.score_f = lambda x: x['search_hit'][0]['search_score']['ionscore']\n",
    "        elif flavour == 'fragpipe':\n",
    "            self.qval_key_f = self.fragpipe_probability\n",
    "            self.scan_no_f = self.fragpipe_scan_no\n",
    "            self.rt_f = self.fragpipe_rt\n",
    "            self.score_f = lambda x: x['search_hit'][0]['search_score']['hyperscore']\n",
    "\n",
    "\n",
    "    def empty_sample(self):\n",
    "        psm_data = [self.empty_scan_no, self.empty_rt, self.empty_pept_seq,\n",
    "                    self.empty_prot_id, self.empty_pstart, self.empty_pend,\n",
    "                    self.empty_isdecoy,  self.empty_calc_mass, self.empty_delta_mass,\n",
    "                    self.empty_qval_key, self.empty_score]\n",
    "        return psm_data\n",
    "\n",
    "    @staticmethod\n",
    "    def mascot_expectation(psm):\n",
    "        return psm['search_hit'][0]['search_score']['expect']\n",
    "\n",
    "    @staticmethod\n",
    "    def mascot_scan_no(psm):\n",
    "        return int(psm['spectrum'].split(' ')[2].split('=')[1])\n",
    "\n",
    "    @staticmethod\n",
    "    def mascot_rt(psm):\n",
    "        return float(psm['search_specification'].split(' ')[2].split('(')[1].rstrip(')'))\n",
    "\n",
    "    @staticmethod\n",
    "    def fragpipe_probability(psm):\n",
    "        return psm['search_hit'][0]['analysis_result'][0]['peptideprophet_result']['probability']\n",
    "\n",
    "    @staticmethod\n",
    "    def fragpipe_scan_no(psm):\n",
    "        return psm['start_scan']\n",
    "\n",
    "    @staticmethod\n",
    "    def fragpipe_rt(psm):\n",
    "        return psm['retention_time_sec']\n",
    "\n",
    "    def get_pepxml_data(self, psm, bovin_lacb, other_lacb, fdb):\n",
    "        rt = self.rt_f(psm)\n",
    "        scan_no = self.scan_no_f(psm)\n",
    "        if 'search_hit' not in psm:\n",
    "            psm_data = [scan_no, rt, self.empty_pept_seq,\n",
    "                        self.empty_prot_id, self.empty_pstart, self.empty_pend,\n",
    "                        self.empty_isdecoy,  self.empty_calc_mass, self.empty_delta_mass,\n",
    "                        self.empty_qval_key]\n",
    "        else:\n",
    "            pept_seq = psm['search_hit'][0]['peptide']\n",
    "            prot_id, pstart, pend = get_prot_info(\n",
    "                pept_seq, psm['search_hit'][0]['proteins'],\n",
    "                bovin_lacb, other_lacb, fdb, field='protein')\n",
    "            isdecoy = pepxml.is_decoy(psm, prefix=decoy_tag)\n",
    "            delta_mass = psm['search_hit'][0]['massdiff']\n",
    "            calc_mass = psm['search_hit'][0]['calc_neutral_pep_mass']\n",
    "            qval_key = self.qval_key_f(psm)\n",
    "            score = self.score_f(psm)\n",
    "            psm_data = [\n",
    "                scan_no, rt, pept_seq,\n",
    "                prot_id, pstart, pend,\n",
    "                isdecoy, calc_mass, delta_mass,\n",
    "                qval_key, score]\n",
    "        return psm_data\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.get_pepxml_data(*args, **kwargs)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run time tests on how to extract scan number and RT from scan titles and data. It could be using split or with regular expressions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Test functions\n",
    "run_timeit = False\n",
    "\n",
    "if run_timeit:\n",
    "    import re\n",
    "    import timeit\n",
    "\n",
    "    string_scan = 'controllerType=0 controllerNumber=1 scan=6905'\n",
    "    string_rt = 'intensity(3084326.2031) scans(7290) rtinseconds(1417.79)'\n",
    "    scan_regex = re.compile(r'scan=(\\d+)')\n",
    "    rt_regex = re.compile(r'rtinseconds\\(([\\d.]+)\\)')\n",
    "\n",
    "    def with_regex(scan, rt):\n",
    "        return (scan_regex.search(scan).group(1),\n",
    "                rt_regex.search(rt).group(1))\n",
    "\n",
    "    def with_split(scan, rt):\n",
    "        return (scan.split(' ')[2].split('=')[1],\n",
    "                rt.split(' ')[2].split('(')[1].rstrip(')'))\n",
    "\n",
    "    def mixed1(scan, rt):\n",
    "        return (scan.split(' ')[2].split('=')[1],\n",
    "                 rt_regex.search(rt).group(1))\n",
    "\n",
    "    def mixed2(scan, rt):\n",
    "        return (scan_regex.search(scan).group(1),\n",
    "                rt.split(' ')[2].split('(')[1].rstrip(')'))\n",
    "\n",
    "    regex_times = (\n",
    "        timeit.Timer(lambda: with_regex(string_scan, string_rt))\n",
    "        .repeat(number=10**5, repeat=20))\n",
    "\n",
    "    split_times = (\n",
    "        timeit.Timer(lambda: with_split(string_scan, string_rt))\n",
    "        .repeat(number=10**5, repeat=20))\n",
    "\n",
    "    mixed1_times = (\n",
    "        timeit.Timer(lambda: mixed1(string_scan, string_rt))\n",
    "        .repeat(number=10**5, repeat=20))\n",
    "\n",
    "    mixed2_times = (\n",
    "        timeit.Timer(lambda: mixed2(string_scan, string_rt))\n",
    "        .repeat(number=10**5, repeat=20))\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(regex_times)):\n",
    "        print(regex_times[i], split_times[i], mixed1_times[i], mixed2_times[i])\n",
    "    print(f'Means:\\n'\n",
    "          f'Using regex: {np.mean(regex_times):.3f}\\n'\n",
    "          f'Using split: {np.mean(split_times):.3f}\\n'\n",
    "          f'Scan with split, RT with regex {np.mean(mixed1_times):.3f}\\n'\n",
    "          f'Scan with regex, RT with split {np.mean(mixed2_times):.3f}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using split is faster"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mascot\n",
    "\n",
    "MASCOT provides a pepxml. But some of the data we need is not directly provided:\n",
    "  - Scan number and RT is extracted from the spectrum title search specification.\n",
    "  - Peptide position is not directly provided, so we search the peptide in the protein sequence and get the position using `get_prot_info`\n",
    "  - We determine if the protein is LACB and if in particular is bovin LACB using `get_prot_info`\n",
    "  - We need to use pyteomics `is_decoy` function to determine if the match is a decoy peptide\n",
    "  - q-values are calculated using the expectation, refined by percolator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mascot_runs = [\n",
    "    'mascot_ns_db1', 'mascot_ns_db2',\n",
    "    'mascot_st_db1', 'mascot_st_db2',\n",
    "    'mascot_t_db1', 'mascot_t_db2']\n",
    "\n",
    "mascot_results_folder = os.path.join(project,'benchmark_results/mascot')\n",
    "mascot_pepxml_target = PepXMLdataExtractor(flavour='mascot')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pepxml_file = os.path.join(mascot_results_folder, 'mascot_st_db1_N0000_filtered.pepxml')\n",
    "mascot_data = pepxml.PepXML(pepxml_file)\n",
    "mascot_data[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "mascot_psm_data = []\n",
    "\n",
    "for mascot in mascot_runs:\n",
    "    print(f'Collecting run {mascot}')\n",
    "    # Ger run DB\n",
    "    dbn = benchmark_table.loc[benchmark_table['Run_id'] == mascot, 'DB'].values[0]\n",
    "    fdb = fasta_db[dbn]\n",
    "    for s in samples:\n",
    "        print(f'\\tSample {s} ... ', end='')\n",
    "        pepxml_file = os.path.join(\n",
    "            mascot_results_folder,  f'{mascot}_{s}_filtered.pepxml'\n",
    "        )\n",
    "\n",
    "        pepxml_data = pepxml.PepXML(pepxml_file)\n",
    "        psm_data = pepxml_data.map(\n",
    "            mascot_pepxml_target, processes=n_procs,\n",
    "            bovin_lacb=bovin_lacb, other_lacb=other_lacb,\n",
    "            fdb=fdb)\n",
    "        psm_data = pd.DataFrame(psm_data)\n",
    "        psm_data.columns = [\n",
    "            'Scan_No', 'RTsec', 'Seq',\n",
    "            'prot_id','start', 'end',\n",
    "            'is_decoy', 'calc_mass', 'delta_mass',\n",
    "            'prob_score', 'score'\n",
    "        ]\n",
    "\n",
    "        psm_data = pepxml.qvalues(\n",
    "            psm_data, key='prob_score', reverse=False, correction=0,\n",
    "            is_decoy='is_decoy', full_output=True)\n",
    "\n",
    "        psm_data['Run_id'] = mascot\n",
    "        psm_data['Sample'] = s\n",
    "        mascot_psm_data.append(psm_data)\n",
    "        print('Done')\n",
    "\n",
    "mascot_psm_data = pd.concat(mascot_psm_data)\n",
    "mascot_psm_data['Scan_idx'] = mascot_psm_data['Scan_No'] - 1\n",
    "mascot_psm_data['score_name'] = 'ionscore'\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fragpipe\n",
    "\n",
    "Fragpipe provides a pepxml.\n",
    "We are reading the interact.pep.xml from each sample. It contains PSMs after Crystal-C and PeptidePrphet\n",
    "\n",
    "Things to consider:\n",
    "- Position of peptide in protein is 1-based in psm.tsv, but we will do the search 0-based with `get_pept_pos`\n",
    "- Delta mass is observed - calculated\n",
    "- q-values are calculated using peptide_prophet probability"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# frag_runs = [\n",
    "#     'fp_ns_db1', 'fp_ns_db2',\n",
    "#     'fp_st_5_db1', 'fp_st_db1', 'fp_st_db2',\n",
    "#     'fp_t_db1', 'fp_t_db2']\n",
    "\n",
    "frag_runs = [\n",
    "    'closed_fp_t_db1', 'closed_fp_st_db1', 'closed_fp_ns_db1',\n",
    "    'fp_ns_db1', 'fp_ns_db2',\n",
    "    'fp_st_db1', 'fp_st_db2',\n",
    "    'fp_t_db1', 'fp_t_db2'\n",
    "]\n",
    "ptm_shepher_folder = 'ptm-shepherd-output'\n",
    "frag_results_folder = os.path.join(project,'benchmark_results/fragpipe')\n",
    "fragpipe_pepxml_target = PepXMLdataExtractor(flavour='fragpipe')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "frag_psm_data = []\n",
    "closed_frag_psm_data = []\n",
    "for fp in frag_runs:\n",
    "    if not fp.startswith('closed'):\n",
    "        continue\n",
    "    print(f'Collecting run {fp}')\n",
    "    fp_path = os.path.join(frag_results_folder, fp)\n",
    "    # Get run db\n",
    "    dbn = benchmark_table.loc[benchmark_table['Run_id'] == fp, 'DB'].values[0]\n",
    "    fdb = fasta_db[dbn]\n",
    "    exp_folders = [\n",
    "        f for f in os.listdir(fp_path)\n",
    "        if f != ptm_shepher_folder and os.path.isdir(os.path.join(fp_path, f))]\n",
    "    for exp in exp_folders:\n",
    "        print(f'\\tSample {exp} ... ', end='')\n",
    "        exp_path = os.path.join(fp_path, exp)\n",
    "        pepxml_file = os.path.join(exp_path, 'interact.pep.xml')\n",
    "        pepxml_data = pepxml.PepXML(pepxml_file)\n",
    "        if len(pepxml_data) == 0:\n",
    "            psm_data = [fragpipe_pepxml_target.empty_sample()]\n",
    "        else:\n",
    "            psm_data = pepxml_data.map(\n",
    "                fragpipe_pepxml_target, processes=n_procs,\n",
    "                bovin_lacb=bovin_lacb, other_lacb=other_lacb,\n",
    "                fdb=fdb)\n",
    "        psm_data = pd.DataFrame(psm_data)\n",
    "        psm_data.columns = [\n",
    "            'Scan_No', 'RTsec', 'Seq',\n",
    "            'prot_id','start', 'end',\n",
    "            'is_decoy', 'calc_mass', 'delta_mass',\n",
    "            'prob_score', 'score'\n",
    "        ]\n",
    "        psm_data['Run_id'] = fp\n",
    "        psm_data['Sample'] = exp\n",
    "        psm_data = pepxml.qvalues(\n",
    "            psm_data, key='prob_score', reverse=True, correction=0,\n",
    "            is_decoy='is_decoy', full_output=True)\n",
    "        if fp.startswith('closed'):\n",
    "            closed_frag_psm_data.append(psm_data)\n",
    "        else:\n",
    "            frag_psm_data.append(psm_data)\n",
    "        print('Done')\n",
    "\n",
    "frag_psm_data = pd.concat(frag_psm_data)\n",
    "frag_psm_data['Scan_idx'] = frag_psm_data['Scan_No'] - 1\n",
    "frag_psm_data['score_name'] = 'hyperscore'\n",
    "\n",
    "closed_frag_psm_data = pd.concat(closed_frag_psm_data)\n",
    "closed_frag_psm_data['Scan_idx'] = closed_frag_psm_data['Scan_No'] - 1\n",
    "closed_frag_psm_data['score_name'] = 'hyperscore'"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# pFind\n",
    "\n",
    "pFind provides a DataFrame with a PSM per row.\n",
    "\n",
    "- In pFind position of peptide in protein is 0-based\n",
    "- Several PSMs per spectra. We need to pick the best scoring\n",
    "- q-value is already given\n",
    "- Delta mass is observed - calculated. But we need to recalculate it from the Modifications it finds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pfind_runs = ['pf_ns_db1', 'pf_ns_db2', 'pf_st_db1', 'pf_st_db2', 'pf_t_db1', 'pf_t_db2']\n",
    "pfind_results_folder = os.path.join(project,'benchmark_results/pFind')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def get_ptms_mass(ptms, unimod_db):\n",
    "    ## Take masses from all PTMs from unimod and calculate the delta mass\n",
    "    ptms_mass = 0\n",
    "    for p in ptms[:-1]:\n",
    "        ptm_name = (\n",
    "            p\n",
    "            .split('(')[0]\n",
    "            .split(',')[1].split('[')[:-1])\n",
    "        ptm_name = '['.join(ptm_name)\n",
    "        ptm_name = map_mods.get(ptm_name, ptm_name)\n",
    "        if ptm_name.startswith(add_colon):\n",
    "            ptm_name = ptm_name.replace('_', ':')\n",
    "        if ptm_name in unknown_mods:\n",
    "            return np.nan\n",
    "        ptms_mass += unimod_db.get(ptm_name, strict=True).monoisotopic_mass\n",
    "    return ptms_mass"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "pfind_psm_data = []\n",
    "for pf in pfind_runs:\n",
    "    print(f'Collecting run {pf} ... ')\n",
    "\n",
    "    dbn = benchmark_table.loc[benchmark_table['Run_id'] == pf, 'DB'].values[0]\n",
    "    fdb = fasta_db[dbn]\n",
    "\n",
    "    pfdf = pd.read_csv(os.path.join(pfind_results_folder, pf, 'pFind-Filtered.spectra'), sep='\\t')\n",
    "    pfdf = pfdf.astype({'File_Name': pd.StringDtype()})\n",
    "    pfdf['Sample'] = pfdf['File_Name'].str.split('.').str[0]\n",
    "    # Pick best PSM per scan\n",
    "    pfdf_filt = (\n",
    "        pfdf.groupby(['Sample', 'Scan_No'], as_index=False)\n",
    "        .apply(lambda x: x.iloc[np.argmin(x['Final_Score']),:]))\n",
    "\n",
    "    # Get protein ID and start and end\n",
    "    pfdf_filt[['prot_id', 'start', 'end']] = (\n",
    "        pfdf_filt[['Sequence', 'Proteins']]\n",
    "        .apply(lambda x: get_prot_info(x['Sequence'], x['Proteins'].split('/'),\n",
    "                                       bovin_lacb, other_lacb, fdb, field=''),\n",
    "               axis=1, result_type='expand'))\n",
    "\n",
    "    # Change NaN modifications to '' (empty string)\n",
    "    pfdf_filt.loc[pfdf_filt['Modification'].isnull(), 'Modification'] = ''\n",
    "\n",
    "    pfdf_filt['delta_mass'] = (\n",
    "        pfdf_filt['Modification']\n",
    "        .str.split(';')\n",
    "        .apply(lambda x: get_ptms_mass(x, unimod_db)))\n",
    "\n",
    "    pfdf_filt['Calc.MH+'] = pfdf_filt['Calc.MH+'] - pfdf_filt['delta_mass']\n",
    "    pfdf_filt['delta_mass'] = pfdf_filt['delta_mass'] + pfdf_filt['Mass_Shift(Exp.-Calc.)']\n",
    "\n",
    "    pfdf_filt = pfdf_filt[[\n",
    "        'Sample', 'Sequence', 'Scan_No', 'start', 'end', 'Q-value', 'prot_id',\n",
    "        'Calc.MH+', 'delta_mass', 'Final_Score', 'Raw_Score']]\n",
    "\n",
    "    rt = pfdf_filt.groupby('Sample', as_index=False)[['Sample', 'Scan_No']].apply(\n",
    "        lambda x: get_rt(x['Scan_No'].to_numpy(), spectra_dict[x.iloc[0,0]]))\n",
    "\n",
    "    pfdf_filt = pd.concat([pfdf_filt, rt.reset_index(drop=True)], axis=1)\n",
    "    pfdf_filt['Run_id'] = pf\n",
    "\n",
    "    pfind_psm_data.append(pfdf_filt)\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "\n",
    "pfind_psm_data = pd.concat(pfind_psm_data)\n",
    "\n",
    "pfind_psm_data = pfind_psm_data.rename(columns={\n",
    "    'Sequence': 'Seq',\n",
    "    'Q-value': 'q',\n",
    "    'Calc.MH+': 'calc_mass',\n",
    "    'Raw_Score': 'score', \n",
    "    'Final_Score': 'prob_score'\n",
    "})\n",
    "\n",
    "pfind_psm_data['score_name'] = 'Final_Score'\n",
    "pfind_psm_data['Scan_idx'] = pfind_psm_data['Scan_No'] - 1\n",
    "pfind_psm_data['is_decoy'] = False\n",
    "# pfind_psm_data.columns = ['Sample', 'Seq', 'Scan_No', 'start', 'end', 'q', 'is_lacb', 'Scan_idx', 'RTsec', 'Run_id']\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MaxQuant\n",
    "\n",
    "We read the text tsv files.\n",
    "MaxQuant gives peptide position in the protein.\n",
    "However, we will recalculate it with respect to the bovin BLG (when it is among the matched proteins)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mq_runs = ['mq_ns_db1', 'mq_ns_db2', 'mq_st_db1', 'mq_st_db2', 'mq_t_db1', 'mq_t_db2']\n",
    "\n",
    "mq_results_folder = os.path.join(project,'benchmark_results/maxquant')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "mq_psm_data = []\n",
    "\n",
    "for mq in mq_runs:\n",
    "    print(f'Collecting run {mq} ... ', end='')\n",
    "\n",
    "    dbn = benchmark_table.loc[benchmark_table['Run_id'] == mq, 'DB'].values[0]\n",
    "    fdb = fasta_db[dbn]\n",
    "\n",
    "    mq_scans = pd.read_csv(os.path.join(mq_results_folder, mq, 'txt/msmsScans.txt'), sep='\\t')\n",
    "    mq_msms = pd.read_csv(os.path.join(mq_results_folder, mq, 'txt/msms.txt'), sep='\\t')\n",
    "    mq_msms = mq_msms[['id', 'Peptide ID', 'Mass error [Da]']]\n",
    "    mq_peps = pd.read_csv(os.path.join(mq_results_folder, mq, 'txt/peptides.txt'), sep='\\t')\n",
    "    mq_peps = mq_peps[['Start position', 'End position', 'id']]\n",
    "    # Change reverse column, to True or False\n",
    "\n",
    "    mq_scans.loc[mq_scans['Reverse'] == '+', 'Reverse'] = True\n",
    "    mq_scans.loc[mq_scans['Reverse'].isna(), 'Reverse'] = False\n",
    "\n",
    "    mq_scans = pepxml.qvalues(mq_scans, key='PEP', reverse=False, correction=0,\n",
    "                              is_decoy='Reverse', full_output=True)\n",
    "\n",
    "    mq_scans = pd.merge(mq_scans, mq_msms, how='left', left_on='MS/MS IDs', right_on='id')\n",
    "\n",
    "    mq_scans = pd.merge(mq_scans, mq_peps, how='left', left_on='Peptide ID', right_on='id')\n",
    "\n",
    "    mq_scans[['prot_id', 'start', 'end']] = (\n",
    "        mq_scans[['Sequence', 'Proteins']]\n",
    "        .apply(lambda x: get_prot_info(x['Sequence'], x['Proteins'].split(';'),\n",
    "                                       bovin_lacb, other_lacb, fdb, field=''),\n",
    "               axis=1, result_type='expand')\n",
    "    )\n",
    "\n",
    "    mq_scans['Run_id'] = mq\n",
    "    mq_scans = mq_scans[[\n",
    "        'Run_id', 'Raw file', 'Sequence', 'Scan number', 'Reverse',\n",
    "        'start', 'end', 'q', 'prot_id', 'Retention time', 'Mass', 'Mass error [Da]', 'PEP', 'Score']]\n",
    "\n",
    "    mq_psm_data.append(mq_scans)\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "mq_psm_data = pd.concat(mq_psm_data)\n",
    "\n",
    "mq_psm_data = mq_psm_data.rename(columns={\n",
    "    'Sequence': 'Seq',\n",
    "    'Raw file': 'Sample',\n",
    "    'Scan number': 'Scan_No',\n",
    "    'Reverse': 'is_decoy',\n",
    "    'Retention time': 'RTsec',\n",
    "    'Mass': 'calc_mass',\n",
    "    'Mass error [Da]': 'delta_mass',\n",
    "    'PEP': 'prob_score',\n",
    "    'Score': 'score'\n",
    "})\n",
    "mq_psm_data['score_name'] = 'Score'\n",
    "mq_psm_data['Scan_idx'] = mq_psm_data['Scan_No'] - 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Alphapept\n",
    "\n",
    "We are reading ALphapept resusts, but they will not be included in the final report.\n",
    "This is because it doesn't have many PSMs and there is no semitryptic option. So for now the results are not very helpful"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ap_runs = ['ap_ns_db1', 'ap_ns_db2', 'ap_t_db2', 'ap_t_db1']\n",
    "ap_runs = []\n",
    "ap_results_folder = os.path.join(project,'benchmark_results/alphapept')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# ap_psms = pd.read_csv(\n",
    "#     os.path.join(ap_results_folder, 'ap_ns_db1', 'results_peptides.csv'),\n",
    "#     index_col=0)\n",
    "# \n",
    "# ap_psms['test_delta'] = ap_psms['mass'] - ap_psms['mass_db']\n",
    "# ap_psms[['prec_offset', 'prec_offset_raw', 'test_delta']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "ap_psm_data = []\n",
    "for ap in ap_runs:\n",
    "    print(f'Collecting run {ap}')\n",
    "    dbn = benchmark_table.loc[benchmark_table['Run_id'] == ap, 'DB'].values[0]\n",
    "    fdb = fasta_db[dbn]\n",
    "\n",
    "    ap_psms = pd.read_csv(\n",
    "        os.path.join(ap_results_folder, ap, 'results_peptides.csv'),\n",
    "        index_col=0)\n",
    "\n",
    "    ap_psms['Run_id'] = ap\n",
    "\n",
    "    ap_psms[['prot_id', 'start', 'end']] = (\n",
    "        ap_psms[['sequence_naked', 'protein']]\n",
    "        .apply(lambda x: get_prot_info(x['sequence_naked'], x['protein'].split(','),\n",
    "                                       bovin_lacb, other_lacb, fdb, field=''),\n",
    "               axis=1, result_type='expand'))\n",
    "\n",
    "    ap_psms = ap_psms[[\n",
    "        'shortname', 'sequence_naked', 'raw_idx', 'scan_no', 'q_value', 'prot_id', 'rt_apex', 'Run_id',\n",
    "        'start', 'end', 'prec_offset', 'mass_db', 'score', 'x_tandem']]\n",
    "\n",
    "    ap_psm_data.append(ap_psms)\n",
    "    print('Done')\n",
    "\n",
    "\n",
    "ap_psm_data = pd.concat(ap_psm_data)\n",
    "ap_psm_data = ap_psm_data.rename(columns={\n",
    "    'shortname': 'Sample',\n",
    "    'sequence_naked': 'Seq',\n",
    "    'raw_idx': 'Scan_idx',\n",
    "    'scan_no': 'Scan_No',\n",
    "    'q_value': 'q',\n",
    "    'rt_apex': 'RTsec',\n",
    "    'prec_offset': 'delta_mass',\n",
    "    'mass_db': 'calc_mass',\n",
    "    'score': 'prob_score',\n",
    "    'x_tandem': 'score'\n",
    "})\n",
    "ap_psm_data['is_decoy'] = False\n",
    "ap_psm_data['score_name'] = 'x_tandem'"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metamorpheus\n",
    "\n",
    "Metamorpheus has a MzIdentML output per sample.\n",
    "We create a function to read MzIdentML PSM data that will also get the peptide positions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mm_runs = ['mm_ns_db1', 'mm_ns_db2', 'mm_t_db1', 'mm_t_db2', 'mm_st_db1', 'mm_st_db2']\n",
    "mm_runs_test = ['mm_t_db1']\n",
    "mm_results_folder = os.path.join(project,'benchmark_results/metamorpheus')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "mzid_data = mzid.MzIdentML(\n",
    "    os.path.join(\n",
    "        project, 'benchmark_results/metamorpheus',\n",
    "        mm_runs[2], 'N0040.mzID'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "mzid_data[1]",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def get_psm_data_mm(psm, bovin_lacb, other_lacb, fdb):\n",
    "    scan_no = int(psm['spectrumID'].split(' ')[2].split('=')[1])\n",
    "    rt = psm['scan start time']\n",
    "\n",
    "    # prot_id = psm['SpectrumIdentificationItem'][0]['PeptideEvidenceRef'][0]['accession']\n",
    "    pept_seq = psm['SpectrumIdentificationItem'][0]['PeptideSequence']\n",
    "    # pstart = psm['SpectrumIdentificationItem'][0]['PeptideEvidenceRef'][0]['start']\n",
    "    # pend = psm['SpectrumIdentificationItem'][0]['PeptideEvidenceRef'][0]['end']\n",
    "\n",
    "    prot_id, pstart, pend = get_prot_info(\n",
    "        pept_seq,\n",
    "        psm['SpectrumIdentificationItem'][0]['PeptideEvidenceRef'],\n",
    "        bovin_lacb, other_lacb, fdb, field='accession')\n",
    "\n",
    "    if 'isDecoy' in psm['SpectrumIdentificationItem'][0]['PeptideEvidenceRef'][0]:\n",
    "        isdecoy = psm['SpectrumIdentificationItem'][0]['PeptideEvidenceRef'][0]['isDecoy']\n",
    "    else:\n",
    "        isdecoy = False\n",
    "    qval = psm['SpectrumIdentificationItem'][0]['PSM-level q-value']\n",
    "    score = psm['SpectrumIdentificationItem'][0]['MetaMorpheus:score']\n",
    "    charge = psm['SpectrumIdentificationItem'][0]['chargeState']\n",
    "    calc_mass = psm['SpectrumIdentificationItem'][0]['calculatedMassToCharge'] * charge\n",
    "    obs_mass = psm['SpectrumIdentificationItem'][0]['experimentalMassToCharge'] * charge\n",
    "    delta_mass = obs_mass - calc_mass\n",
    "\n",
    "    data = [\n",
    "        scan_no,\n",
    "        pept_seq,\n",
    "        rt,\n",
    "        prot_id, pstart, pend,\n",
    "        qval, isdecoy,\n",
    "        delta_mass, calc_mass,\n",
    "        score\n",
    "    ]\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "metam_psm_data = []\n",
    "\n",
    "for mm in mm_runs:\n",
    "    print(f'Collecting run {mm}')\n",
    "    dbn = benchmark_table.loc[benchmark_table['Run_id'] == mm, 'DB'].values[0]\n",
    "    fdb = fasta_db_metam[dbn]\n",
    "    mm_path = os.path.join(mm_results_folder, mm)\n",
    "    for s in samples:\n",
    "        print(f'\\tSample {s} ... ', end='')\n",
    "        mzid_file = os.path.join(\n",
    "            project, 'benchmark_results/metamorpheus', mm, f'{s}.mzID')\n",
    "        if not os.path.exists(mzid_file):\n",
    "            psm_data = pd.DataFrame(\n",
    "                [[mm, s, -1, '', np.nan,\n",
    "                  '', -1, -1, np.nan, False,\n",
    "                  np.nan, np.nan, np.nan]],\n",
    "                columns = [\n",
    "                    'Run_id', 'Sample', 'Scan_No', 'Seq', 'RTsec',\n",
    "                    'prot_id', 'start', 'end', 'q', 'is_decoy',\n",
    "                    'delta_mass', 'calc_mass', 'score'])\n",
    "            metam_psm_data.append(psm_data)\n",
    "            print('Done')\n",
    "            continue\n",
    "        mzid_data = mzid.MzIdentML(\n",
    "            os.path.join(\n",
    "                project, 'benchmark_results/metamorpheus',\n",
    "                mm, f'{s}.mzID'))\n",
    "        psm_data = mzid_data.map(\n",
    "            get_psm_data_mm, processes=n_procs, fdb=fdb,\n",
    "            bovin_lacb=bovin_lacb, other_lacb=other_lacb)\n",
    "        psm_data = pd.DataFrame(psm_data)\n",
    "        psm_data.columns = [\n",
    "            'Scan_No', 'Seq', 'RTsec', 'prot_id','start', 'end',\n",
    "            'q', 'is_decoy',\n",
    "            'delta_mass', 'calc_mass', 'score']\n",
    "        psm_data['Run_id'] = mm\n",
    "        psm_data['Sample'] = s\n",
    "        metam_psm_data.append(psm_data)\n",
    "        print('Done')\n",
    "\n",
    "metam_psm_data = pd.concat(metam_psm_data)\n",
    "metam_psm_data['Scan_idx'] = metam_psm_data['Scan_No'] - 1\n",
    "metam_psm_data['score_name'] = 'metamorpheus_score'\n",
    "metam_psm_data['prob_score'] = np.nan"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "metam_psm_data.query(\"q < 0.05 and Run_id == 'mm_t_db1'\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Combine Database Search\n",
    "Combine results form:\n",
    "- Mascot\n",
    "- Fragpipe\n",
    "- pFind\n",
    "- MaxQuant\n",
    "- Metamorpheus\n",
    "\n",
    "Then add the run information for each PSM\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "psm_data_df = pd.concat([frag_psm_data, pfind_psm_data, mq_psm_data,\n",
    "                         mascot_psm_data, metam_psm_data, closed_frag_psm_data])\n",
    "\n",
    "psm_data_df = pd.merge(psm_data_df, benchmark_table, on='Run_id')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "psm_data_df['is_lacb'] = psm_data_df['prot_id'].isin(bovin_lacb)\n",
    "psm_data_df = psm_data_df[psm_data_df['Seq'].notna()]\n",
    "psm_data_df = psm_data_df[(psm_data_df['Seq'] != '') & (psm_data_df['Seq'] != ' ')]\n",
    "# Calculate isoelectric point for the peptides\n",
    "psm_data_df['pI'] = psm_data_df['Seq'].apply(lambda x: electrochem.pI(x) if x != '' and x != ' ' else np.nan)\n",
    "psm_data_df['gravy'] = psm_data_df['Seq'].apply(lambda x: electrochem.gravy(x) if x != '' and x != ' ' and 'U' not in x else np.nan)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Write DBs PSMs data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "psm_data_file = os.path.join(project, 'analysis_results', 'psms_data.csv')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "source": "psm_data_df.to_csv(os.path.join(project, 'analysis_results', 'psms_data.csv'))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If we want to start from here\n",
    "psm_data_df = pd.read_csv(psm_data_file, index_col=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DeNovoGUI\n",
    "\n",
    "- DirecTag score is expectation. Lower is better\n",
    "- PepNovo is rank score. Higher is better\n",
    "- pNovo+ is graph score. Higher is better\n",
    "- Novor is score from decision trees and machinelearning on spectral libs. Higher is better"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "denovo_runs = ['db1', 'db2']\n",
    "denovo_software = [\n",
    "    ('novor', 'Novor Score'),\n",
    "    ('directag', 'DirecTag E-value'),\n",
    "    ('pepnovo', 'PepNovo Score'),\n",
    "    ('pnovo', 'pNovo+ Score')\n",
    "]\n",
    "denovo_results_folder =  os.path.join(project,'benchmark_results/denovo_gui')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "denovo_psm_data = []\n",
    "for denovo in denovo_runs:\n",
    "    print(f'Reading de novo {denovo} run...')\n",
    "    psm_data = pd.read_csv(\n",
    "        os.path.join(denovo_results_folder, f'denovo_{denovo}.txt'),\n",
    "        sep='\\t', index_col=False\n",
    "    )\n",
    "\n",
    "    for sw, score in denovo_software:\n",
    "        print(f'\\tExtracting data from {sw} ... ', end='')\n",
    "        psm_data_sw = psm_data.rename(columns = {\n",
    "            'File Name': 'Sample',\n",
    "            'Spectrum Title': 'Scan_No',\n",
    "            'Retention Time (s)': 'RTsec',\n",
    "            'Measured m/z': 'obs_mz',\n",
    "            'Measured Charge': 'charge',\n",
    "            'Peptide': 'Seq',\n",
    "            'Modified Sequence': 'ModSeq',\n",
    "            score: 'score',\n",
    "            'Peptide Mass Error (Da)': 'delta_mz'})\n",
    "        psm_data_sw = (\n",
    "            psm_data_sw\n",
    "            .loc[psm_data_sw['score'].notna(),\n",
    "                 ['Sample', 'Scan_No', 'RTsec', 'ModSeq',\n",
    "                  'obs_mz', 'charge', 'Seq', 'score', 'delta_mz']])\n",
    "        psm_data_sw['Sample'] = psm_data_sw['Sample'].str.split('.').str[0]\n",
    "        psm_data_sw['Scan_No'] = psm_data_sw['Scan_No'].str.split('.').str[1]\n",
    "        psm_data_sw['Run_id'] = sw + '_' + denovo\n",
    "        psm_data_sw['charge'] = psm_data_sw['charge'].str.rstrip('+').astype('int')\n",
    "        psm_data_sw['calc_mass'] = (psm_data_sw['obs_mz'] - psm_data_sw['delta_mz']) * psm_data_sw['charge']\n",
    "        psm_data_sw['delta_mass'] = psm_data_sw['delta_mz'] * psm_data_sw['charge']\n",
    "        psm_data_sw = psm_data_sw.drop(columns=['obs_mz', 'charge', 'delta_mz'])\n",
    "\n",
    "        denovo_psm_data.append(psm_data_sw)\n",
    "        print('Done')\n",
    "\n",
    "denovo_psm_data = pd.concat(denovo_psm_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "denovo_psm_data = pd.merge(denovo_psm_data, benchmark_table, on='Run_id')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "denovo_psm_data['Sample'] = denovo_psm_data['Sample'].replace(sample_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "denovo_data_file = os.path.join(project, 'analysis_results', 'denovo_psms_data.csv')\n",
    "denovo_psm_data.to_csv(denovo_data_file, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Count PSMs\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('Counting PSMs at each FDR threshold')\n",
    "# psm_data_df = pd.read_csv(psm_data_file, index_col=0)\n",
    "# Thresholds of q_values to count PSMs\n",
    "q_val_thresholds = np.arange(0.05, 0, -0.00001)\n",
    "psm_counts_df = (\n",
    "    psm_data_df[(psm_data_df['is_decoy'] != True) & (psm_data_df['q'] < 0.05)]\n",
    "    .groupby(['Run_id', 'Sample'], as_index=True)[['q']]\n",
    "    .apply(lambda x: pd.DataFrame([[qt, np.sum(x['q']<qt)] for qt in q_val_thresholds]))\n",
    "    .reset_index().drop('level_2', axis=1)\n",
    ")\n",
    "psm_counts_df.columns = ['Run_id', 'Sample', 'fdr', 'n_psm']\n",
    "# Merge with scan counts\n",
    "psm_counts_df = pd.merge(psm_counts_df, n_scans, on='Sample')\n",
    "psm_counts_df['f_psm'] = psm_counts_df['n_psm']/psm_counts_df['n_ms2scans']\n",
    "# Merge with run info\n",
    "psm_counts_df = pd.merge(psm_counts_df, benchmark_table, on='Run_id')\n",
    "psm_counts_df = psm_counts_df.sort_values(['Run settings', 'Sample'])\n",
    "psm_counts_df.to_csv(os.path.join(project, 'analysis_results', 'psms_counts', 'psms_counts.csv'), index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Turn to position long format"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "psm_data_df['pep_positions'] = psm_data_df['start'] + psm_data_df['Seq'].str.len().apply(lambda x: np.arange(1, x+1, 1))\n",
    "psm_data_df['pep_letters'] = psm_data_df['Seq'].str.split('').str[1:-1]\n",
    "psm_data_df['gt_005fdr'] = psm_data_df['q'] > 0.05\n",
    "psm_data_df['pep_pI'] = psm_data_df['pI'] * psm_data_df['Seq'].str.len().apply(lambda x: np.repeat(1, x))\n",
    "\n",
    "position_counts = (\n",
    "    psm_data_df\n",
    "    .explode(['pep_positions', 'pep_letters', 'pep_pI'], ignore_index=True)\n",
    "    .groupby(['Run_id', 'Sample', 'is_lacb', 'gt_005fdr', 'pep_positions', 'pep_letters'])\n",
    "    .agg(count=pd.NamedAgg(column='pep_letters', aggfunc='size'), mean_pI=pd.NamedAgg(column='pep_pI', aggfunc='mean'))\n",
    "    .reset_index())\n",
    "\n",
    "position_counts['total_counts'] = (\n",
    "    position_counts\n",
    "    .groupby(['Run_id', 'Sample', 'is_lacb', 'gt_005fdr', 'pep_positions'])['count']\n",
    "    .transform('sum'))\n",
    "position_counts['mean_pI'] = (\n",
    "    position_counts.groupby(['Run_id', 'Sample', 'is_lacb', 'gt_005fdr', 'pep_positions'])['mean_pI']\n",
    "    .transform('max'))\n",
    "position_counts = pd.merge(position_counts, benchmark_table, on='Run_id')\n",
    "position_counts['rel_count'] = position_counts['count'] / position_counts['total_counts']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Here we merge with the actual BLG positions and amino acids\n",
    "# To spot where there are wrong positions\n",
    "\n",
    "# Get bovin BLG seuqences\n",
    "bovin_lacb_accessions = [\n",
    "    'sp|P02754A|LACB_BOVIN',\n",
    "    'sp|P02754B|LACB_BOVIN',\n",
    "    'sp|P02754C|LACB_BOVIN',\n",
    "    'sp|P02754D|LACB_BOVIN'\n",
    "]\n",
    "bovin_lacb_seqs = [fasta_db['DB1'][i] for i in bovin_lacb_accessions]\n",
    "seq_list = []\n",
    "pos_list = []\n",
    "for blg_var in bovin_lacb_seqs:\n",
    "    seq = str(blg_var.seq)\n",
    "    seq_list.extend(seq)\n",
    "    pos_list.extend(list(range(1, len(seq)+1)))\n",
    "\n",
    "blg_df = pd.DataFrame({'pep_letters': seq_list, 'pep_positions': pos_list})\n",
    "blg_df = blg_df.drop_duplicates().sort_values('pep_positions')\n",
    "blg_df['is_lacb'] = True\n",
    "blg_df['correct'] = True\n",
    "\n",
    "# Merge positions counts with blg_df\n",
    "position_counts = position_counts.merge(\n",
    "    blg_df, how='left', on=['pep_letters', 'pep_positions', 'is_lacb'])\n",
    "position_counts.loc[position_counts['correct'].isna(), 'correct'] = False\n",
    "\n",
    "# Remove non_lacb (decoys are also removed)\n",
    "position_counts = position_counts[position_counts['is_lacb'] == True]\n",
    "\n",
    "# Mirror incorrect or coming from q_val > 0.05 PSMs\n",
    "mirror = (position_counts['correct'] == False) & (position_counts['gt_005fdr'] == True)\n",
    "\n",
    "position_counts['count_mirror'] = position_counts['count']\n",
    "position_counts['rel_count_mirror'] = position_counts['rel_count']\n",
    "position_counts.loc[position_counts['correct'] == False, 'count_mirror'] = (\n",
    "        position_counts.loc[position_counts['correct'] == False, 'count_mirror'] * -1)\n",
    "position_counts.loc[position_counts['correct'] == False, 'rel_count_mirror'] = (\n",
    "        position_counts.loc[position_counts['correct'] == False, 'rel_count_mirror'] * -1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "position_counts.to_csv(os.path.join(project, 'analysis_results', 'dbsearch_position_letters.csv'), index=False)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read data\n",
    "Read psm_data to continue analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "psm_data_file = os.path.join(project, 'analysis_results', 'psms_data.csv')\n",
    "psm_data_df = pd.read_csv(psm_data_file, index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "position_counts_file = os.path.join(project, 'analysis_results', 'dbsearch_position_letters.csv')\n",
    "position_counts = pd.read_csv(position_counts_file)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
